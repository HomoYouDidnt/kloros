"""
Vosk Direct Audio Mode - Direct Vosk integration with persistent recognizers
Fixes stateless HTTP issues by using Vosk streaming API correctly
"""

import numpy as np
import threading
import time
import json
import os
from typing import Optional, Callable, Dict, Any
import sys
from pathlib import Path

# Add project root to path
_repo_root = Path(__file__).resolve().parent.parent.parent
if str(_repo_root) not in sys.path:
    sys.path.insert(0, str(_repo_root))

try:
    import vosk
except ImportError:
    vosk = None

from src.audio.capture import create_audio_backend, AudioInputBackend


class VoskDirectAudioMode:
    """
    Direct Vosk integration with persistent recognizers.
    Implements proper streaming recognition without HTTP overhead.
    """

    def __init__(
        self,
        sample_rate: int = 48000,
        model_path: str = "/home/kloros/kloros_models/vosk/model",
        audio_backend: str = "sounddevice",
        audio_device: Optional[int] = None,
        audio_init_timeout: float = 5.0,
    ):
        self.sample_rate = sample_rate
        self.model_path = model_path
        self.audio_backend_name = audio_backend
        self.audio_device = audio_device
        self.audio_init_timeout = audio_init_timeout

        # Vosk components
        self.model: Optional[vosk.Model] = None
        self.wake_recognizer: Optional[vosk.KaldiRecognizer] = None
        self.general_recognizer: Optional[vosk.KaldiRecognizer] = None

        # Audio backend
        self.audio_backend: Optional[AudioInputBackend] = None

        # Processing
        self.running = False
        self.recognition_thread: Optional[threading.Thread] = None

        # Configuration
        self.wake_phrases = ["kloros"]
        self.wake_conf_min = 0.65
        self.wake_mode = True  # True = wake detection, False = general recognition

        # Callbacks
        self.wake_callback: Optional[Callable] = None
        self.recognition_callback: Optional[Callable] = None

        # Periodic finalization
        self.last_finalize_time = time.time()
        self.finalize_interval = 3.0  # Force FinalResult every 3 seconds

    def set_callbacks(
        self,
        wake_detected: Optional[Callable] = None,
        recognition: Optional[Callable] = None,
    ):
        """Set callbacks for events."""
        self.wake_callback = wake_detected
        self.recognition_callback = recognition

    def _load_vosk_model(self) -> bool:
        """Load Vosk model and create recognizers."""
        if not vosk:
            print("[vosk-direct] ERROR: vosk module not available")
            return False

        try:
            print(f"[vosk-direct] Loading Vosk model from {self.model_path}")
            self.model = vosk.Model(self.model_path)
            print("[vosk-direct] Model loaded successfully")

            # Create wake recognizer (no grammar - model doesn't support it)
            self.wake_recognizer = vosk.KaldiRecognizer(self.model, 16000)
            self.wake_recognizer.SetWords(True)
            print(f"[vosk-direct] Wake recognizer created for phrases: {self.wake_phrases}")

            # Create general recognizer
            self.general_recognizer = vosk.KaldiRecognizer(self.model, 16000)
            self.general_recognizer.SetWords(True)
            print("[vosk-direct] General recognizer created")

            return True

        except Exception as e:
            print(f"[vosk-direct] Failed to load model: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _resample_to_16k(self, audio_chunk: np.ndarray, orig_sr: int) -> np.ndarray:
        """Resample audio from original sample rate to 16 kHz."""
        if orig_sr == 16000:
            return audio_chunk

        num_samples_16k = int(len(audio_chunk) * 16000 / orig_sr)
        from scipy import signal
        resampled = signal.resample(audio_chunk, num_samples_16k)
        return resampled.astype(np.float32)

    def _apply_gain(self, audio_chunk: np.ndarray, target_rms: float = 0.1) -> np.ndarray:
        """Apply automatic gain control to boost quiet audio."""
        rms = np.sqrt(np.mean(audio_chunk ** 2))
        
        if rms > 0.001:  # Only boost if there's actual signal
            gain = target_rms / rms
            gain = min(gain, 10.0)  # Limit max gain to 10x
            return audio_chunk * gain
        return audio_chunk

    def _recognition_loop(self):
        """Background thread for audio capture and recognition."""
        print("[vosk-direct] Recognition thread started")
        chunk_count = 0

        try:
            # Use chunks() iterator to get audio
            for chunk in self.audio_backend.chunks(block_ms=200):  # 200ms chunks
                if not self.running:
                    break
                
                chunk_count += 1
                
                # Show heartbeat every 50 chunks (~10 seconds)
                if chunk_count % 50 == 0:
                    mode = "wake" if self.wake_mode else "general"
                    print(f"[vosk-direct] Processing audio (chunk {chunk_count}, mode={mode})")

                # Resample to 16kHz for Vosk
                audio_16k = self._resample_to_16k(chunk, self.sample_rate)
                
                # Apply automatic gain for quiet microphones
                audio_16k = self._apply_gain(audio_16k, target_rms=0.1)

                # Convert float32 audio to int16 for Vosk
                audio_int16 = (audio_16k * 32767).astype(np.int16)
                audio_bytes = audio_int16.tobytes()

                # Select recognizer based on mode
                recognizer = self.wake_recognizer if self.wake_mode else self.general_recognizer

                # Feed chunk to Vosk
                if recognizer.AcceptWaveform(audio_bytes):
                    # Complete result available
                    result = json.loads(recognizer.Result())
                    self._handle_result(result, final=True)
                else:
                    # Check partial result
                    partial = json.loads(recognizer.PartialResult())
                    if partial.get("partial"):
                        if chunk_count % 25 == 0:  # Log every 5 seconds
                            print(f"[vosk-direct] Partial: {partial.get('partial')}")

                # Periodic finalization to force results
                now = time.time()
                if now - self.last_finalize_time > self.finalize_interval:
                    final = json.loads(recognizer.FinalResult())
                    if final.get("text"):
                        self._handle_result(final, final=True)
                    
                    # Recreate recognizer to reset state
                    if self.wake_mode:
                        self.wake_recognizer = vosk.KaldiRecognizer(self.model, 16000)
                        self.wake_recognizer.SetWords(True)
                    else:
                        self.general_recognizer = vosk.KaldiRecognizer(self.model, 16000)
                        self.general_recognizer.SetWords(True)
                    
                    self.last_finalize_time = now

        except Exception as e:
            print(f"[vosk-direct] Recognition loop error: {e}")
            import traceback
            traceback.print_exc()

        print("[vosk-direct] Recognition thread stopped")

    def _handle_result(self, result: Dict[str, Any], final: bool = False):
        """Handle recognition result."""
        text = result.get("text", "").strip()
        
        if not text:
            return

        # Extract confidence (Vosk provides per-word confidence)
        confidence = 0.0
        if "result" in result:
            confidences = [w.get("conf", 0.0) for w in result["result"]]
            confidence = sum(confidences) / len(confidences) if confidences else 0.0

        print(f"[vosk-direct] Recognized: '{text}' (conf={confidence:.2f}, final={final})")

        # Wake word detection mode
        if self.wake_mode:
            text_lower = text.lower()
            for wake_phrase in self.wake_phrases:
                if wake_phrase.lower() in text_lower:
                    print(f"[vosk-direct] Wake detected: {text}")
                    if self.wake_callback:
                        self.wake_callback({
                            "text": text,
                            "matched_phrase": wake_phrase,
                            "confidence": confidence,
                            "timestamp": time.time(),
                        })
                    return

        # General recognition mode
        else:
            if confidence > 0.3 or final:
                if self.recognition_callback:
                    self.recognition_callback({
                        "type": "speech_recognized",
                        "text": text,
                        "confidence": confidence,
                        "timestamp": time.time(),
                    })

    def _open_audio_backend_threaded(self, result_container: Dict[str, Any]):
        """Thread worker to open audio backend with isolation."""
        try:
            self.audio_backend.open(
                sample_rate=self.sample_rate,
                channels=1,
                device=self.audio_device
            )
            result_container["success"] = True
            result_container["error"] = None
        except Exception as e:
            result_container["success"] = False
            result_container["error"] = str(e)
            import traceback
            result_container["traceback"] = traceback.format_exc()

    def start(self) -> bool:
        """Start the audio mode with direct Vosk integration."""
        if self.running:
            print("[vosk-direct] Already running")
            return True

        # Load Vosk model
        if not self._load_vosk_model():
            print("[vosk-direct] Failed to load Vosk model")
            return False

        # Initialize audio backend
        try:
            self.audio_backend = create_audio_backend(self.audio_backend_name)

            if not self.audio_backend:
                print("[vosk-direct] Failed to create audio backend")
                return False

            # Thread-isolated audio stream opening with timeout
            print(f"[vosk-direct] Opening audio stream (timeout={self.audio_init_timeout}s)...")
            
            result_container: Dict[str, Any] = {}
            open_thread = threading.Thread(
                target=self._open_audio_backend_threaded,
                args=(result_container,),
                daemon=True
            )
            
            open_thread.start()
            open_thread.join(timeout=self.audio_init_timeout)

            if open_thread.is_alive():
                print(f"[vosk-direct] ERROR: Audio stream open timed out after {self.audio_init_timeout}s")
                self.audio_backend = None
                return False

            if not result_container.get("success"):
                error = result_container.get("error", "Unknown error")
                print(f"[vosk-direct] Audio backend error: {error}")
                return False

            print(f"[vosk-direct] Audio stream opened (SR={self.sample_rate}Hz, resampling to 16kHz)")

        except Exception as e:
            print(f"[vosk-direct] Audio backend initialization error: {e}")
            import traceback
            traceback.print_exc()
            return False

        # Start recognition thread
        self.running = True
        self.recognition_thread = threading.Thread(
            target=self._recognition_loop,
            daemon=True,
        )
        self.recognition_thread.start()

        print("[vosk-direct] Started successfully")
        return True

    def stop(self):
        """Stop the audio mode."""
        print("[vosk-direct] Stopping...")
        self.running = False

        if self.recognition_thread:
            self.recognition_thread.join(timeout=2.0)

        if self.audio_backend:
            self.audio_backend.close()

        print("[vosk-direct] Stopped")

    def set_recognition_mode(self, mode: str):
        """Set recognition mode: 'wake' or 'general'."""
        self.wake_mode = (mode == "wake")
        print(f"[vosk-direct] Mode set to: {mode}")

    def reset_recognizers(self):
        """Reset recognizer state."""
        if self.model:
            self.wake_recognizer = vosk.KaldiRecognizer(self.model, 16000)
            self.wake_recognizer.SetWords(True)
            self.general_recognizer = vosk.KaldiRecognizer(self.model, 16000)
            self.general_recognizer.SetWords(True)
            print("[vosk-direct] Recognizers reset")

    def is_healthy(self) -> bool:
        """Check if system is healthy."""
        return (
            self.running
            and self.model is not None
            and self.recognition_thread
            and self.recognition_thread.is_alive()
        )
