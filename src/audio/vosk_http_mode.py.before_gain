"""
Vosk HTTP Audio Mode - Simple audio capture + HTTP recognition
Replaces separated_audio multiprocessing with HTTP service calls
Eliminates PortAudio/ALSA conflicts and threading deadlocks
"""

import numpy as np
import threading
import time
from typing import Optional, Callable, Dict, Any
import sys
from pathlib import Path

# Add project root to path
_repo_root = Path(__file__).resolve().parent.parent.parent
if str(_repo_root) not in sys.path:
    sys.path.insert(0, str(_repo_root))

from src.audio.vosk_http_client import VoskHTTPClient
from src.audio.capture import create_audio_backend, AudioInputBackend


class VoskHTTPAudioMode:
    """
    Simple audio mode using HTTP Vosk service.
    NO multiprocessing - just audio capture + HTTP calls.
    Production-grade with timeout-based audio initialization.
    """

    def __init__(
        self,
        sample_rate: int = 48000,
        vosk_url: str = "http://localhost:8080",
        audio_backend: str = "sounddevice",
        audio_device: Optional[int] = None,
        audio_init_timeout: float = 5.0,
    ):
        self.sample_rate = sample_rate
        self.vosk_client = VoskHTTPClient(vosk_url)
        self.audio_backend_name = audio_backend
        self.audio_device = audio_device
        self.audio_init_timeout = audio_init_timeout

        # Audio backend
        self.audio_backend: Optional[AudioInputBackend] = None

        # Processing
        self.running = False
        self.recognition_thread: Optional[threading.Thread] = None

        # Configuration
        self.wake_phrases = ["kloros"]
        self.wake_conf_min = 0.65
        self.wake_mode = True  # True = wake detection, False = general recognition

        # Callbacks
        self.wake_callback: Optional[Callable] = None
        self.recognition_callback: Optional[Callable] = None

    def set_callbacks(
        self,
        wake_detected: Optional[Callable] = None,
        recognition: Optional[Callable] = None,
    ):
        """Set callbacks for events."""
        self.wake_callback = wake_detected
        self.recognition_callback = recognition

    def _resample_to_16k(self, audio_chunk: np.ndarray, orig_sr: int) -> np.ndarray:
        """Resample audio from original sample rate to 16 kHz.

        Args:
            audio_chunk: Audio samples at original sample rate
            orig_sr: Original sample rate

        Returns:
            Resampled audio at 16 kHz
        """
        if orig_sr == 16000:
            return audio_chunk

        # Calculate number of samples at 16 kHz
        num_samples_16k = int(len(audio_chunk) * 16000 / orig_sr)

        # Resample using scipy
        from scipy import signal
        resampled = signal.resample(audio_chunk, num_samples_16k)
        return resampled.astype(np.float32)

    def _recognition_loop(self):
        """Background thread for audio capture and recognition."""
        print("[vosk-http-mode] Recognition thread started")
        chunk_count = 0

        try:
            # Use chunks() iterator to get audio
            for chunk in self.audio_backend.chunks(block_ms=200):  # 200ms chunks
                if not self.running:
                    break
                
                chunk_count += 1
                # Show heartbeat every 50 chunks (~10 seconds)
                if chunk_count % 50 == 0:
                    mode = "wake" if self.wake_mode else "general"
                    print(f"[vosk-http-mode] Processing audio (chunk {chunk_count}, mode={mode})")

                # Resample to 16kHz for Vosk
                audio_16k = self._resample_to_16k(chunk, self.sample_rate)

                # Convert float32 audio to int16 for Vosk
                audio_int16 = (audio_16k * 32767).astype(np.int16)
                audio_bytes = audio_int16.tobytes()

                # Send to Vosk HTTP service with correct sample rate
                result = self.vosk_client.recognize_audio(audio_bytes, 16000)

                if "error" in result:
                    print(f"[vosk-http-mode] Recognition error: {result['error']}")
                    continue

                text = result.get("text", "").strip()
                confidence = result.get("confidence", 0.0)

                if not text:
                    continue

                # Wake word detection mode
                if self.wake_mode:
                    text_lower = text.lower()
                    for wake_phrase in self.wake_phrases:
                        if wake_phrase.lower() in text_lower:
                            print(f"[vosk-http-mode] Wake detected: {text}")
                            if self.wake_callback:
                                self.wake_callback({
                                    "text": text,
                                    "matched_phrase": wake_phrase,
                                    "confidence": confidence,
                                    "timestamp": time.time(),
                                })
                            break
                else:
                    # General recognition mode
                    if confidence > 0.3:
                        print(f"[vosk-http-mode] Recognized: {text} (conf={confidence:.2f})")
                        if self.recognition_callback:
                            self.recognition_callback({
                                "type": "speech_recognized",
                                "text": text,
                                "confidence": confidence,
                                "timestamp": time.time(),
                            })

        except Exception as e:
            print(f"[vosk-http-mode] Recognition loop error: {e}")
            import traceback
            traceback.print_exc()

        print("[vosk-http-mode] Recognition thread stopped")

    def _open_audio_backend_threaded(self, result_container: Dict[str, Any]):
        """Thread worker to open audio backend with isolation.
        
        Args:
            result_container: Dict to store result {"success": bool, "error": str}
        """
        try:
            self.audio_backend.open(
                sample_rate=self.sample_rate,
                channels=1,
                device=self.audio_device
            )
            result_container["success"] = True
            result_container["error"] = None
        except Exception as e:
            result_container["success"] = False
            result_container["error"] = str(e)
            import traceback
            result_container["traceback"] = traceback.format_exc()

    def start(self) -> bool:
        """Start the audio mode with timeout-based initialization."""
        if self.running:
            print("[vosk-http-mode] Already running")
            return True

        # Check Vosk service
        if not self.vosk_client.is_ready():
            print("[vosk-http-mode] ERROR: Vosk service not ready")
            return False

        print("[vosk-http-mode] Vosk service ready")

        # Initialize audio backend
        try:
            self.audio_backend = create_audio_backend(self.audio_backend_name)

            if not self.audio_backend:
                print("[vosk-http-mode] Failed to create audio backend")
                return False

            # Thread-isolated audio stream opening with timeout
            print(f"[vosk-http-mode] Opening audio stream (timeout={self.audio_init_timeout}s)...")
            
            result_container: Dict[str, Any] = {}
            open_thread = threading.Thread(
                target=self._open_audio_backend_threaded,
                args=(result_container,),
                daemon=True
            )
            
            open_thread.start()
            open_thread.join(timeout=self.audio_init_timeout)

            if open_thread.is_alive():
                # Timeout occurred - thread is still blocked
                print(f"[vosk-http-mode] ERROR: Audio stream open timed out after {self.audio_init_timeout}s")
                print("[vosk-http-mode] This usually indicates PipeWire/ALSA permission issues")
                print("[vosk-http-mode] Run as user with audio session or check XDG_RUNTIME_DIR")
                self.audio_backend = None
                return False

            # Check result
            if not result_container.get("success"):
                error = result_container.get("error", "Unknown error")
                print(f"[vosk-http-mode] Audio backend error: {error}")
                if "traceback" in result_container:
                    print(result_container["traceback"])
                return False

            print(f"[vosk-http-mode] Audio stream opened (SR={self.sample_rate}Hz, resampling to 16kHz)")

        except Exception as e:
            print(f"[vosk-http-mode] Audio backend initialization error: {e}")
            import traceback
            traceback.print_exc()
            return False

        # Start recognition thread
        self.running = True
        self.recognition_thread = threading.Thread(
            target=self._recognition_loop,
            daemon=True,
        )
        self.recognition_thread.start()

        print("[vosk-http-mode] Started successfully")
        return True

    def stop(self):
        """Stop the audio mode."""
        print("[vosk-http-mode] Stopping...")
        self.running = False

        if self.recognition_thread:
            self.recognition_thread.join(timeout=2.0)

        if self.audio_backend:
            self.audio_backend.close()

        print("[vosk-http-mode] Stopped")

    def set_recognition_mode(self, mode: str):
        """Set recognition mode: 'wake' or 'general'."""
        self.wake_mode = (mode == "wake")
        print(f"[vosk-http-mode] Mode set to: {mode}")

    def reset_recognizers(self):
        """Reset recognizer state (for compatibility with separated_audio API)."""
        pass

    def is_healthy(self) -> bool:
        """Check if system is healthy."""
        return (
            self.running
            and self.vosk_client.is_ready()
            and self.recognition_thread
            and self.recognition_thread.is_alive()
        )
