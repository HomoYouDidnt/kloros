# KLoROS Model Configuration - Single Source of Truth
# All ML assets with exact versions and checksums

[embeddings]
model = "nomic-ai/nomic-embed-text-v1.5"
normalize = true
dim = 768  # Full dimension (can be sliced to 384 via Matryoshka)
truncate_dim = 384  # Use 384-dim slice for storage efficiency
sha256 = ""  # Computed by kloros-vec-rebuild
trust_remote_code = true  # Required for nomic models

[embeddings.fallbacks]
models = [
    "all-MiniLM-L6-v2",
    "all-distilroberta-v1",
    "all-MiniLM-L12-v2"
]

# Unified Ollama Architecture
# Single Ollama service (port 11434) loads models on-demand
# Models: qwen2.5:7b-instruct (chat) | qwen2.5-coder:7b (code) | deepseek-r1:7b (deep reasoning)

[llm.main]
model = "qwen2.5:7b-instruct-q4_K_M"
url = "http://127.0.0.1:11434"
api_type = "ollama"
temperature = 0.7
max_tokens = 2048
context_window = 32768  # 32k context

[llm.code]
model = "qwen2.5-coder:7b"
url = "http://127.0.0.1:11434"
api_type = "ollama"
temperature = 0.2
max_tokens = 4096
context_window = 32768  # 32k context

[llm.deep]
model = "deepseek-r1:7b"
url = "http://127.0.0.1:11434"
api_type = "ollama"
temperature = 0.5
max_tokens = 4096
context_window = 32768  # 32k context

[stt.whisper]
variant = "openai-whisper"
model = "small"
device = "cuda"
sha256 = ""

[stt.vosk]
model_path = "/home/kloros/models/vosk/model"
sha256 = ""

[tts.piper]
voice = "en_US-lessac-medium"
model_path = "/home/kloros/models/piper"
sha256 = ""

[speaker]
embedding_model = "speechbrain/spkrec-ecapa-voxceleb"
sha256 = ""

[vector_store]
backend = "qdrant"  # Options: chromadb, qdrant
server_url = "http://localhost:6333"  # Qdrant server URL (server mode for concurrent access)
persist_directory = "~/.kloros/qdrant_storage"  # Only used if server_url is not set (file mode)
collection_name = "kloros_memory"
distance_metric = "cosine"

[routing]
planner = "agentflow@1.3.2"
validator = "rules+state@0.4.0"
semantic_matcher = "cosine"
threshold = 0.3
