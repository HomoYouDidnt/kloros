#!/usr/bin/env python3
"""
Orchestration Coordinator - Main state machine for KLoROS orchestration.

Manages the closed loop between D-REAM, PHASE, and baseline updates.
"""

import os
import json
import logging
from datetime import datetime
from pathlib import Path
from enum import Enum, auto
from typing import Optional

try:
    from zoneinfo import ZoneInfo
except ImportError:
    from backports.zoneinfo import ZoneInfo  # Python < 3.9

from . import phase_trigger
from . import dream_trigger
from . import promotion_daemon
from . import baseline_manager
from . import state_manager
from . import metrics
from . import intent_queue

logger = logging.getLogger(__name__)

PROCESSED_EPOCHS = Path("/home/kloros/.kloros/processed/epochs.jsonl")
INTENT_DIR = Path("/home/kloros/.kloros/intents")


class OrchestratorState(Enum):
    """Orchestrator states."""
    IDLE = auto()
    PHASE_SCHEDULED = auto()
    PHASE_RUNNING = auto()
    PHASE_DONE = auto()
    INGEST_PHASE_RESULTS = auto()
    PROMOTION_PENDING = auto()
    PREP_HEURISTICS = auto()
    DREAM_CYCLE_ONDEMAND = auto()


def _in_phase_window() -> bool:
    """
    Check if current time is in PHASE window (3-7 AM America/New_York).

    Uses DST-aware timezone handling.
    """
    try:
        now = datetime.now(ZoneInfo("America/New_York"))
        return 3 <= now.hour < 7
    except Exception as e:
        logger.error(f"Error checking PHASE window: {e}")
        return False


def _phase_done_today() -> bool:
    """
    Check if PHASE has already completed today.

    Reads processed epoch ledger for today's date.
    """
    if not PROCESSED_EPOCHS.exists():
        return False

    try:
        today = datetime.now(ZoneInfo("America/New_York")).date().isoformat()

        with open(PROCESSED_EPOCHS, 'r') as f:
            for line in f:
                if not line.strip():
                    continue
                entry = json.loads(line)
                epoch_date = entry.get("date")
                if epoch_date == today:
                    return True

        return False

    except Exception as e:
        logger.error(f"Error checking processed epochs: {e}")
        return False


def _mark_phase_done(epoch_id: str) -> None:
    """Mark PHASE epoch as processed."""
    PROCESSED_EPOCHS.parent.mkdir(parents=True, exist_ok=True)

    entry = {
        "epoch_id": epoch_id,
        "date": datetime.now(ZoneInfo("America/New_York")).date().isoformat(),
        "ts": datetime.now().timestamp()
    }

    with open(PROCESSED_EPOCHS, 'a') as f:
        f.write(json.dumps(entry) + '\n')


def _has_new_promotions() -> bool:
    """Check if there are unacknowledged promotions."""
    unacked = promotion_daemon.scan_unacked_promotions()
    return len(unacked) > 0


def _has_idle_intents() -> bool:
    """Check if there are intent files from observer or idle reflection."""
    if not INTENT_DIR.exists():
        return False

    return len(list(INTENT_DIR.glob("*.json"))) > 0


def _process_intent(intent_path: Path) -> str:
    """
    Process a single intent file and trigger appropriate action.

    Args:
        intent_path: Path to intent JSON file

    Returns:
        Action taken: "PHASE_TRIGGERED", "DREAM_TRIGGERED", "ALERT_SENT", "INVALID"
    """
    try:
        intent = json.loads(intent_path.read_text())
        intent_type = intent.get("intent_type", "")

        logger.info(f"Processing intent: {intent_type} (priority={intent.get('priority', 0)})")

        # Handle different intent types
        if intent_type == "trigger_phase_promotion_cluster":
            # Promotion cluster detected - trigger PHASE validation
            logger.info(f"Promotion cluster: {intent.get('reason', '')}")

            result = phase_trigger.run_epoch(force=False)

            if result.exit_code == 0:
                metrics.phase_runs_total.labels(result="success").inc()
                _mark_phase_done(result.epoch_id)
                _archive_intent(intent_path, "processed")
                return "PHASE_TRIGGERED"
            else:
                metrics.phase_runs_total.labels(result="failure").inc()
                _archive_intent(intent_path, "failed")
                return "PHASE_FAILED"

        elif intent_type == "trigger_dream":
            # D-REAM trigger - check mode
            mode = intent.get("data", {}).get("mode", "")
            logger.info(f"D-REAM trigger: mode={mode}, reason={intent.get('reason', '')}")

            if mode == "config_tuning":
                # Config tuning mode - autonomous parameter optimization
                try:
                    import sys
                    sys.path.insert(0, '/home/kloros')
                    from src.dream.config_tuning import ConfigTuningRunner

                    # Check if self-healing is enabled
                    healing_mode = os.environ.get("KLR_SELF_HEALING_MODE", "disabled")
                    if healing_mode not in ["dev", "prod"]:
                        logger.warning(f"Self-healing disabled (KLR_SELF_HEALING_MODE={healing_mode})")
                        _archive_intent(intent_path, "skipped")
                        return "HEALING_DISABLED"

                    runner = ConfigTuningRunner()
                    run = runner.run(intent.get("data", {}))

                    if run.status == "success" and run.promoted:
                        logger.info(f"Config tuning success: promoted {run.best_candidate.candidate_id}")
                        _archive_intent(intent_path, "processed")
                        return "CONFIG_TUNED"
                    elif run.status == "rate_limited":
                        logger.warning(f"Config tuning rate limited: {run.subsystem}")
                        _archive_intent(intent_path, "rate_limited")
                        return "RATE_LIMITED"
                    else:
                        logger.warning(f"Config tuning failed: {run.status}")
                        _archive_intent(intent_path, "failed")
                        return "CONFIG_TUNING_FAILED"

                except Exception as e:
                    logger.error(f"Config tuning error: {e}", exc_info=True)
                    _archive_intent(intent_path, "error")
                    return "ERROR"
            else:
                logger.warning(f"Unknown D-REAM mode: {mode}")
                _archive_intent(intent_path, "unknown")
                return "UNKNOWN_MODE"

        elif intent_type == "integration_fix":
            # Integration fix - apply code patch directly
            question_id = intent.get("data", {}).get("question_id", "unknown")
            hypothesis = intent.get("data", {}).get("hypothesis", "")
            fix_spec = intent.get("data", {}).get("fix_specification", {})
            autonomy = intent.get("data", {}).get("autonomy_level", 2)

            logger.info(f"Integration fix: {hypothesis} (autonomy={autonomy})")

            if autonomy < 3:
                logger.info(f"Autonomy {autonomy} < 3, skipping auto-apply (requires manual approval)")
                _archive_intent(intent_path, "manual_approval_required")
                return "MANUAL_APPROVAL_REQUIRED"

            try:
                from src.self_heal.actions import INTEGRATION_ACTIONS_AVAILABLE
                if not INTEGRATION_ACTIONS_AVAILABLE:
                    logger.error("Integration actions not available")
                    _archive_intent(intent_path, "unavailable")
                    return "INTEGRATION_ACTIONS_UNAVAILABLE"

                from src.self_heal.actions_integration import (
                    AddMissingCallAction,
                    AddNullCheckAction,
                    ConsolidateDuplicatesAction
                )

                action_type = fix_spec.get("action") or fix_spec.get("action_type") or fix_spec.get("fix_type")
                action_params = fix_spec.get("params") or fix_spec.get("parameters", {})

                if action_type == "add_missing_call":
                    action = AddMissingCallAction(name="add_missing_call", params=action_params)
                elif action_type == "add_null_check":
                    action = AddNullCheckAction(name="add_null_check", params=action_params)
                elif action_type == "consolidate_duplicates":
                    action = ConsolidateDuplicatesAction(name="consolidate_duplicates", params=action_params)
                else:
                    logger.error(f"Unknown action type: {action_type}")
                    _archive_intent(intent_path, "unknown_action")
                    return "UNKNOWN_ACTION"

                logger.info(f"Applying {action_type} with params: {action_params}")
                result = action.apply(kloros_instance=None)  # Coordinator runs standalone

                # Handle bool or dict return values
                if isinstance(result, bool):
                    if result:
                        logger.info(f"✅ Integration fix applied: {question_id}")
                        _archive_intent(intent_path, "applied")
                        return "FIX_APPLIED"
                    else:
                        logger.error(f"❌ Integration fix failed (returned False)")
                        _archive_intent(intent_path, "failed")
                        return "FIX_FAILED"
                elif isinstance(result, dict):
                    if result.get("status") == "success":
                        logger.info(f"✅ Integration fix applied: {question_id}")
                        _archive_intent(intent_path, "applied")
                        return "FIX_APPLIED"
                    else:
                        logger.error(f"❌ Integration fix failed: {result.get('error')}")
                        _archive_intent(intent_path, "failed")
                        return "FIX_FAILED"
                else:
                    logger.error(f"❌ Integration fix returned unexpected type: {type(result)}")
                    _archive_intent(intent_path, "error")
                    return "ERROR"

            except Exception as e:
                logger.error(f"Error applying integration fix: {e}", exc_info=True)
                _archive_intent(intent_path, "error")
                return "ERROR"

        elif intent_type == "spica_spawn_request":
            from src.dream.config_tuning.llm_code_generator import LLMCodeGenerator
            from src.dream.config_tuning.spica_spawner import spawn_instance, apply_code_patch, run_tests_in_instance
            from src.kloros.orchestration.escrow_manager import EscrowManager

            question_id = intent.get("data", {}).get("question_id", "unknown")
            question = intent.get("data", {}).get("question", "")
            hypothesis = intent.get("data", {}).get("hypothesis", "")
            fix_context = intent.get("data", {}).get("fix_context", {})
            validation = intent.get("data", {}).get("validation", {})

            logger.info(f"[spica_spawn] Autonomous fix attempt: {question_id}")

            evidence = fix_context.get("evidence", [])
            report_path_str = fix_context.get("analysis_report")
            target_files = fix_context.get("target_files", [])

            if not target_files:
                logger.error(f"[spica_spawn] No target files specified for {question_id}")
                _archive_intent(intent_path, "no_target_files")
                return "SPICA_SPAWN_FAILED"

            try:
                llm_generator = LLMCodeGenerator()
                report_path = Path(report_path_str) if report_path_str else None
                target_file = Path(target_files[0])

                logger.info(f"[spica_spawn] Generating code patch for {target_file}")
                patch = llm_generator.generate_fix_patch(
                    question=question,
                    hypothesis=hypothesis,
                    evidence=evidence,
                    report_path=report_path,
                    target_file=target_file
                )

                if not patch:
                    logger.error(f"[spica_spawn] LLM failed to generate patch for {question_id}")
                    _archive_intent(intent_path, "llm_generation_failed")
                    return "SPICA_SPAWN_FAILED"

                logger.info(f"[spica_spawn] Generated patch ({len(patch)} chars)")

            except Exception as e:
                logger.error(f"[spica_spawn] LLM generation error: {e}", exc_info=True)
                _archive_intent(intent_path, f"llm_error_{type(e).__name__}")
                return "SPICA_SPAWN_FAILED"

            try:
                logger.info(f"[spica_spawn] Creating SPICA instance for {question_id}")
                spica_instance = spawn_instance(
                    candidate={},
                    parent_id=None,
                    notes=f"Autonomous fix attempt: {question_id}"
                )

                logger.info(f"[spica_spawn] Created {spica_instance.spica_id}")

            except Exception as e:
                logger.error(f"[spica_spawn] SPICA spawn error: {e}", exc_info=True)
                _archive_intent(intent_path, f"spawn_error_{type(e).__name__}")
                return "SPICA_SPAWN_FAILED"

            try:
                relative_target = target_file.relative_to("/home/kloros") if target_file.is_absolute() else target_file

                logger.info(f"[spica_spawn] Applying patch to {relative_target}")
                patch_success = apply_code_patch(
                    instance_dir=spica_instance.instance_dir,
                    target_file=relative_target,
                    patch_content=patch
                )

                if not patch_success:
                    logger.error(f"[spica_spawn] Failed to apply patch to {relative_target}")
                    _archive_intent(intent_path, "patch_application_failed")
                    return "SPICA_SPAWN_FAILED"

            except Exception as e:
                logger.error(f"[spica_spawn] Patch application error: {e}", exc_info=True)
                _archive_intent(intent_path, f"patch_error_{type(e).__name__}")
                return "SPICA_SPAWN_FAILED"

            if validation.get("run_tests", False):
                try:
                    test_command = validation.get("test_command", "pytest")
                    # Ensure test runs in SPICA venv using uv with full path
                    if not test_command.startswith("uv run") and not test_command.startswith("/"):
                        # Use full path to uv to avoid PATH issues
                        uv_path = "/home/kloros/.local/bin/uv"
                        test_command = f"{uv_path} run {test_command}"
                    logger.info(f"[spica_spawn] Running tests: {test_command}")

                    test_result = run_tests_in_instance(
                        instance_dir=spica_instance.instance_dir,
                        test_command=test_command
                    )

                    if not test_result["success"] and validation.get("require_pass", True):
                        logger.error(f"[spica_spawn] Tests failed for {question_id}")
                        logger.error(f"Test output: {test_result['output'][:500]}")
                        _archive_intent(intent_path, "tests_failed")
                        return "SPICA_SPAWN_FAILED"

                    logger.info(f"[spica_spawn] Tests passed for {question_id}")

                except Exception as e:
                    logger.error(f"[spica_spawn] Test execution error: {e}", exc_info=True)
                    _archive_intent(intent_path, f"test_error_{type(e).__name__}")
                    return "SPICA_SPAWN_FAILED"
            else:
                test_result = {}

            try:
                escrow = EscrowManager()
                escrow_id = escrow.add_to_escrow(
                    spica_id=spica_instance.spica_id,
                    question_id=question_id,
                    instance_dir=spica_instance.instance_dir,
                    test_results=test_result
                )

                logger.info(f"[spica_spawn] Added {spica_instance.spica_id} to escrow: {escrow_id}")
                _archive_intent(intent_path, f"escrowed_{escrow_id}")
                return "CURIOSITY_SPAWNED"

            except Exception as e:
                logger.error(f"[spica_spawn] Escrow error: {e}", exc_info=True)
                _archive_intent(intent_path, f"escrow_error_{type(e).__name__}")
                return "SPICA_SPAWN_FAILED"

        elif intent_type.startswith("curiosity_"):
            # Curiosity-driven intent - spawn D-REAM exploration
            question_id = intent.get("data", {}).get("question_id", "unknown")
            hypothesis = intent.get("data", {}).get("hypothesis", "")
            dream_experiment = intent.get("data", {}).get("dream_experiment", {})

            logger.info(f"Curiosity exploration: {hypothesis} (question_id={question_id})")

            # Nov 1, 2025: Removed TODO, implemented actual D-REAM spawner
            if dream_experiment:
                try:
                    # Spawn D-REAM experiment from curiosity question
                    # Note: dream_trigger runs ALL experiments in dream.yaml, not just one
                    # The run_tag is used for logging/tracking only
                    result = dream_trigger.run_once(
                        topic=None,
                        run_tag=f"curiosity_{question_id}"
                    )

                    logger.info(f"✅ Spawned D-REAM experiment for curiosity question {question_id}: {result}")
                    _archive_intent(intent_path, "spawned")
                    return "CURIOSITY_SPAWNED"

                except Exception as e:
                    logger.error(f"❌ Failed to spawn D-REAM experiment for {question_id}: {e}")
                    # Still log for review
                    suggestions_log = Path("/home/kloros/logs/orchestrator/curiosity_experiments.jsonl")
                    suggestions_log.parent.mkdir(parents=True, exist_ok=True)
                    with open(suggestions_log, 'a') as f:
                        f.write(json.dumps({
                            "ts": datetime.now().isoformat(),
                            "intent": intent,
                            "dream_experiment": dream_experiment,
                            "error": str(e)
                        }) + '\n')
                    _archive_intent(intent_path, "error")
                    return "CURIOSITY_ERROR"
            else:
                logger.warning(f"No dream_experiment in curiosity intent {question_id}")
                _archive_intent(intent_path, "incomplete")
                return "CURIOSITY_INCOMPLETE"

        elif intent_type.startswith("suggest_"):
            # Suggestion intent - log for review
            logger.info(f"Suggestion: {intent.get('reason', '')}")

            # Write to suggestions log for user review
            suggestions_log = Path("/home/kloros/logs/orchestrator/suggestions.jsonl")
            suggestions_log.parent.mkdir(parents=True, exist_ok=True)

            with open(suggestions_log, 'a') as f:
                f.write(json.dumps({
                    "ts": datetime.now().isoformat(),
                    "intent": intent
                }) + '\n')

            _archive_intent(intent_path, "processed")
            return "SUGGESTION_LOGGED"

        elif intent_type.startswith("alert_"):
            # High-priority alert - requires attention
            logger.warning(f"ALERT: {intent.get('reason', '')}")

            # Write to alerts log
            alerts_log = Path("/home/kloros/logs/orchestrator/alerts.jsonl")
            alerts_log.parent.mkdir(parents=True, exist_ok=True)

            with open(alerts_log, 'a') as f:
                f.write(json.dumps({
                    "ts": datetime.now().isoformat(),
                    "intent": intent
                }) + '\n')

            _archive_intent(intent_path, "processed")
            return "ALERT_SENT"

        else:
            logger.warning(f"Unknown intent type: {intent_type}")
            _archive_intent(intent_path, "unknown")
            return "INVALID"

    except Exception as e:
        logger.error(f"Error processing intent {intent_path.name}: {e}")
        _archive_intent(intent_path, "error")
        return "ERROR"


def _archive_intent(intent_path: Path, status: str) -> None:
    """
    Archive processed intent file.

    Args:
        intent_path: Path to intent file
        status: Processing status ("processed", "failed", "error", "unknown")
    """
    archive_dir = INTENT_DIR / "processed" / status
    archive_dir.mkdir(parents=True, exist_ok=True)

    # Add timestamp to filename
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    new_name = f"{ts}_{intent_path.name}"

    intent_path.rename(archive_dir / new_name)


def _is_orchestration_enabled() -> bool:
    """Check if orchestration mode is enabled."""
    mode = os.environ.get("KLR_ORCHESTRATION_MODE", "disabled")
    return mode == "enabled"


def tick() -> str:
    """
    Single orchestration cycle (called by timer every minute).

    Returns:
        Action taken: "NOOP", "PHASE_DONE", "DREAM_CYCLE", "ERROR"
    """
    # Check if orchestration is enabled
    if not _is_orchestration_enabled():
        logger.debug("Orchestration disabled (KLR_ORCHESTRATION_MODE != enabled)")
        metrics.orchestrator_tick_total.labels(outcome="disabled").inc()
        return "DISABLED"

    lock = None
    try:
        # Acquire orchestrator lock
        try:
            lock = state_manager.acquire("orchestrator")
        except RuntimeError as e:
            logger.warning(f"Could not acquire lock: {e}")
            metrics.orchestrator_lock_contention.inc()
            metrics.orchestrator_tick_total.labels(outcome="contention").inc()
            return "CONTENTION"

        # State machine logic
        action = "NOOP"

        # ALWAYS process curiosity questions first (independent of other actions)
        from . import curiosity_processor
        curiosity_result = curiosity_processor.process_curiosity_feed()
        if curiosity_result["intents_emitted"] > 0:
            logger.info(f"Curiosity processor emitted {curiosity_result['intents_emitted']} new intents")

        # ALWAYS check for new D-REAM winners and deploy them (closes autonomous loop)
        from . import winner_deployer
        try:
            deploy_result = winner_deployer.run_deployment_cycle()
            if deploy_result["deployed"] > 0:
                logger.info(f"Winner deployer: deployed {deploy_result['deployed']} new winners")
        except Exception as e:
            logger.error(f"Winner deployer failed: {e}")

        # Priority 1: PHASE window
        if _in_phase_window() and not _phase_done_today():
            logger.info("Starting PHASE epoch (in window, not done today)")

            result = phase_trigger.run_epoch(force=False)

            # Record metrics
            if result.exit_code == 0:
                metrics.phase_runs_total.labels(result="success").inc()
                metrics.phase_duration_seconds.observe(result.duration_s)

                # Mark as processed
                _mark_phase_done(result.epoch_id)

                action = "PHASE_DONE"
                logger.info(f"PHASE epoch {result.epoch_id} completed successfully")
            elif result.exit_code == 124:
                metrics.phase_runs_total.labels(result="timeout").inc()
                action = "PHASE_TIMEOUT"
                logger.error("PHASE timeout")
            else:
                metrics.phase_runs_total.labels(result="failure").inc()
                action = "PHASE_FAILED"
                logger.error(f"PHASE failed with exit code {result.exit_code}")

        # Priority 2: Process promotions (trigger D-REAM if needed)
        elif _has_new_promotions():
            logger.info("Unacknowledged promotions detected, triggering D-REAM")

            result = dream_trigger.run_once(topic=None)

            # Record metrics
            if result.exit_code == 0:
                metrics.dream_runs_total.labels(result="success").inc()
                metrics.dream_duration_seconds.observe(result.duration_s)
                action = "DREAM_CYCLE"
                logger.info(f"D-REAM cycle completed (tag={result.run_tag})")
            elif result.exit_code == 124:
                metrics.dream_runs_total.labels(result="timeout").inc()
                action = "DREAM_TIMEOUT"
                logger.error("D-REAM timeout")
            else:
                metrics.dream_runs_total.labels(result="failure").inc()
                action = "DREAM_FAILED"
                logger.error(f"D-REAM failed with exit code {result.exit_code}")

        # Priority 3: Process Observer/Curiosity intents
        elif _has_idle_intents():
            logger.info("Processing intents from Observer/Curiosity")

            # Use queue middleware for deduplication and priority management
            queue_result = intent_queue.process_queue()

            # Log queue stats if cleanup occurred
            stats = queue_result["stats"]
            if stats["deduplicated"] > 0 or stats["pruned"] > 0 or stats["dropped"] > 0:
                logger.info(f"Intent queue: depth={queue_result['queue_depth']}, "
                           f"dedup={stats['deduplicated']}, "
                           f"pruned={stats['pruned']}, "
                           f"dropped={stats['dropped']}")

            # Process multiple intents per tick (up to 10)
            max_intents_per_tick = 10
            intents_processed = 0
            action = "NOOP"

            while intents_processed < max_intents_per_tick and queue_result["next_intent"]:
                intent_file = queue_result["next_intent"]
                action = _process_intent(intent_file)
                logger.info(f"Intent processed ({intents_processed+1}/{max_intents_per_tick}): {intent_file.name} -> {action}")
                intents_processed += 1

                # Get next intent if available
                if intents_processed < max_intents_per_tick:
                    queue_result = intent_queue.process_queue()
                    if not queue_result["next_intent"]:
                        break

            if intents_processed == 0:
                action = "NOOP"

        else:
            # Nothing to do
            logger.debug("Orchestrator tick: no action needed")
            action = "NOOP"

        metrics.orchestrator_tick_total.labels(outcome=action.lower()).inc()
        return action

    except Exception as e:
        logger.error(f"Orchestrator error: {e}", exc_info=True)
        metrics.orchestrator_tick_total.labels(outcome="error").inc()
        return "ERROR"

    finally:
        if lock:
            state_manager.release(lock)
