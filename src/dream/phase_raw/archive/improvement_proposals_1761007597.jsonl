{"id": "active_code_repair_1761007597", "domain": "code_repair", "params": {"issue_type": "enhancement", "priority": "medium", "proposed_change": null, "target_files": ["/home/kloros/src/reasoning/query_classifier.py"], "failure_count": 0, "family": "unknown", "common_errors": {}}, "metrics": {"score": 0.6, "novelty": 0.3, "latency_ms": 0.0, "holdout_ok": true, "wer": 0.0, "failure_count": 0}, "notes": "Context-Aware Query Classification Fix\n\nPROBLEM: KLoROS was losing context mid-conversation because the query classifier was too aggressive. Mid-conversation confirmations like \"Absolutely, yes.\" and \"Let's think about that.\" were being classified as conversational greetings, triggering canned responses (\"What can I do for you?\") that bypassed the LLM entirely.\n\nROOT CAUSE: query_classifier.py classified queries without considering whether we were in an active conversation. It treated all short phrases and acknowledgments as standalone greetings.\n\nFIX IMPLEMENTED:\n1. Added conversation_history parameter to classify_query() function\n2. Added context awareness check: in_conversation = conversation_history and len(conversation_history) > 0\n3. Modified two conditional checks to prevent canned responses when in active conversation:\n   - Line 105: if not has_substantive_content and not in_conversation\n   - Line 123: if word_count < 5 and not in_conversation\n4. Integrated into local_rag_backend.py to pass conversation history from conversation_logger\n\nVERIFICATION:\n- Tested with \"Absolutely, yes.\" - without context: conversational, with context: ambiguous (uses LLM)\n- Tested with \"Let's think about that.\" - with context: ambiguous (uses LLM)\n- Genuine greetings still classified correctly as conversational\n\nIMPACT: KLoROS now maintains conversation context properly, preventing the \"What can I do for you?\" response loop that was frustrating users mid-conversation.\n\nFILES MODIFIED:\n- /home/kloros/src/reasoning/query_classifier.py (context-aware classification logic)\n- /home/kloros/src/reasoning/local_rag_backend.py (pass conversation_history from conversation_logger)\n"}
