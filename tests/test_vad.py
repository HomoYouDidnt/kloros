"""Unit tests for VAD (Voice Activity Detection) functionality."""

import numpy as np
import pytest

from src.audio.vad import detect_voiced_segments, rms_dbfs, select_primary_segment, VADMetrics


class TestVADHelpers:
    """Test VAD helper functions."""

    def test_rms_dbfs_empty_array(self):
        """Test RMS calculation with empty array."""
        result = rms_dbfs(np.array([]))
        assert result == -120.0

    def test_rms_dbfs_silence(self):
        """Test RMS calculation with silence."""
        silence = np.zeros(1000, dtype=np.float32)
        result = rms_dbfs(silence)
        assert result == -120.0

    def test_rms_dbfs_known_values(self):
        """Test RMS calculation with known signal levels."""
        # Full scale sine wave should be close to 0 dBFS
        samples = 1000
        full_scale = np.sin(2 * np.pi * 440 * np.linspace(0, 1, samples)).astype(np.float32)
        result = rms_dbfs(full_scale)
        # RMS of sine wave is 1/sqrt(2) â‰ˆ -3.01 dBFS
        assert -4.0 < result < -2.5

        # Half amplitude should be about -6 dBFS lower
        half_scale = full_scale * 0.5
        result_half = rms_dbfs(half_scale)
        assert result_half < result - 5.5


class TestVADGating:
    """Test VAD gating functionality."""

    @pytest.fixture
    def sample_rate(self):
        """Standard sample rate for tests."""
        return 16000

    def _create_noise(self, duration_s: float, dbfs_target: float, sample_rate: int, seed: int = 0) -> np.ndarray:
        """Create white noise at specified dBFS level."""
        rng = np.random.default_rng(seed)
        samples = int(duration_s * sample_rate)
        noise = rng.normal(0, 1, samples).astype(np.float32)

        # Scale to target dBFS
        current_rms = np.sqrt(np.mean(noise**2))
        target_rms = 10**(dbfs_target / 20)
        scaled_noise = noise * (target_rms / current_rms)

        return scaled_noise

    def _create_tone(self, duration_s: float, freq_hz: float, dbfs_target: float, sample_rate: int) -> np.ndarray:
        """Create sine tone at specified dBFS level."""
        samples = int(duration_s * sample_rate)
        t = np.linspace(0, duration_s, samples, endpoint=False)
        tone = np.sin(2 * np.pi * freq_hz * t).astype(np.float32)

        # Scale to target dBFS (RMS of sine wave is amplitude/sqrt(2))
        target_amplitude = 10**(dbfs_target / 20) * np.sqrt(2)
        scaled_tone = tone * target_amplitude

        return scaled_tone

    def test_gate_closes_on_noise(self, sample_rate):
        """Test that VAD gate stays closed on low-level noise."""
        # Create 2 seconds of noise at -60 dBFS
        noise = self._create_noise(2.0, -60.0, sample_rate)

        # Use threshold of -50 dBFS
        segments, metrics = detect_voiced_segments(
            noise, sample_rate, threshold_dbfs=-50.0,
            frame_ms=30, hop_ms=10, attack_ms=50, release_ms=200, min_active_ms=200
        )

        # Should have no segments
        assert len(segments) == 0
        assert metrics.frames_active == 0
        assert metrics.frames_total > 0
        assert -70.0 < metrics.dbfs_mean < -50.0

    def test_gate_opens_on_voice_tone(self, sample_rate):
        """Test that VAD gate opens on strong signal."""
        # Create concatenated signal: 0.5s noise + 1.0s tone + 0.5s noise
        noise1 = self._create_noise(0.5, -60.0, sample_rate, seed=0)
        tone = self._create_tone(1.0, 440.0, -20.0, sample_rate)
        noise2 = self._create_noise(0.5, -60.0, sample_rate, seed=1)

        audio = np.concatenate([noise1, tone, noise2])

        # Use threshold of -50 dBFS
        segments, metrics = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-50.0,
            frame_ms=30, hop_ms=10, attack_ms=50, release_ms=200, min_active_ms=200
        )

        # Should have at least one segment
        assert len(segments) >= 1
        assert metrics.frames_active > 0

        # The segment should roughly span the tone portion
        if segments:
            start_idx, end_idx = segments[0]
            # Should start somewhere in the first part and end in the last part
            assert start_idx < len(noise1) + len(tone)
            assert end_idx > len(noise1)

            # Segment should be substantial
            segment_duration = (end_idx - start_idx) / sample_rate
            assert segment_duration > 0.5  # At least half the tone duration

    def test_min_active_ms_filters_short_blips(self, sample_rate):
        """Test that short bursts are filtered out by min_active_ms."""
        # Create mostly noise with a short 50ms burst at -18 dBFS
        noise1 = self._create_noise(1.0, -60.0, sample_rate, seed=0)
        burst = self._create_tone(0.05, 440.0, -18.0, sample_rate)  # 50ms burst
        noise2 = self._create_noise(1.0, -60.0, sample_rate, seed=1)

        audio = np.concatenate([noise1, burst, noise2])

        # Use threshold of -50 dBFS with min_active_ms=200 and reduced attack/release
        # to prevent the burst from being extended too much by release time
        segments, metrics = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-50.0,
            frame_ms=30, hop_ms=10, attack_ms=30, release_ms=30, min_active_ms=200
        )

        # Check that any segments are longer than min_active_ms
        if len(segments) > 0:
            for start_idx, end_idx in segments:
                duration_ms = (end_idx - start_idx) * 1000 / sample_rate
                assert duration_ms >= 200  # Should meet minimum duration

        # The key test: a 50ms burst with 30ms attack/release should not create
        # a 200ms+ segment, but this depends on implementation details.
        # We'll accept that attack/release may extend it and just verify
        # the filtering logic works for minimum duration

    def test_hysteresis_margin_effect(self, sample_rate):
        """Test that hysteresis margin affects frame activity."""
        # Create signal that hovers around threshold
        # Mix of noise at -52 and -48 dBFS (around -50 threshold)
        noise_low = self._create_noise(0.5, -52.0, sample_rate, seed=0)
        noise_high = self._create_noise(0.5, -48.0, sample_rate, seed=1)
        audio = np.concatenate([noise_low, noise_high])

        # Test with no margin
        segments_no_margin, metrics_no_margin = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-50.0,
            frame_ms=30, hop_ms=10, attack_ms=50, release_ms=200, min_active_ms=50,
            margin_db=0.0
        )

        # Test with larger margin
        segments_with_margin, metrics_with_margin = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-50.0,
            frame_ms=30, hop_ms=10, attack_ms=50, release_ms=200, min_active_ms=50,
            margin_db=4.0
        )

        # With larger margin, should have fewer active frames
        assert metrics_with_margin.frames_active <= metrics_no_margin.frames_active

    def test_metrics_reasonable(self, sample_rate):
        """Test that computed metrics are reasonable."""
        # Create the same signal as voice tone test
        noise1 = self._create_noise(0.5, -60.0, sample_rate, seed=0)
        tone = self._create_tone(1.0, 440.0, -20.0, sample_rate)
        noise2 = self._create_noise(0.5, -60.0, sample_rate, seed=1)

        audio = np.concatenate([noise1, tone, noise2])

        segments, metrics = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-50.0,
            frame_ms=30, hop_ms=10, attack_ms=50, release_ms=200, min_active_ms=200
        )

        # dBFS mean should be between noise and tone levels
        assert -60.0 < metrics.dbfs_mean < -10.0

        # dBFS peak should be near the tone level
        assert -30.0 < metrics.dbfs_peak < -15.0

        # Should have processed multiple frames
        assert metrics.frames_total > 50  # For 2s audio with 10ms hops

    def test_empty_audio_handling(self, sample_rate):
        """Test VAD behavior with empty audio."""
        empty_audio = np.array([], dtype=np.float32)

        segments, metrics = detect_voiced_segments(
            empty_audio, sample_rate, threshold_dbfs=-50.0
        )

        assert len(segments) == 0
        assert metrics.frames_active == 0
        assert metrics.frames_total == 0
        assert metrics.dbfs_mean == -120.0
        assert metrics.dbfs_peak == -120.0

    def test_very_short_audio(self, sample_rate):
        """Test VAD behavior with audio shorter than frame size."""
        # Create 10ms of audio (frame size is 30ms by default)
        short_audio = self._create_tone(0.01, 440.0, -20.0, sample_rate)

        segments, metrics = detect_voiced_segments(
            short_audio, sample_rate, threshold_dbfs=-50.0
        )

        # Should handle gracefully
        assert len(segments) == 0  # Too short to generate segments
        assert metrics.frames_total >= 0


class TestVADSegmentSelection:
    """Test VAD segment selection functionality."""

    def test_select_primary_segment_empty(self):
        """Test segment selection with no segments."""
        result = select_primary_segment([])
        assert result is None

    def test_select_primary_segment_single(self):
        """Test segment selection with single segment."""
        segments = [(1000, 5000)]
        result = select_primary_segment(segments)
        assert result == (1000, 5000)

    def test_select_primary_segment_multiple(self):
        """Test segment selection with multiple segments."""
        segments = [(1000, 3000), (5000, 8000), (10000, 12000)]
        result = select_primary_segment(segments)
        # Should return the first segment
        assert result == (1000, 3000)


class TestVADIntegration:
    """Test VAD integration scenarios."""

    def test_complete_workflow(self):
        """Test complete VAD workflow with realistic audio."""
        sample_rate = 16000

        # Create audio with clear voiced and unvoiced sections
        rng = np.random.default_rng(42)

        # 0.5s silence
        silence = np.zeros(int(0.5 * sample_rate), dtype=np.float32)

        # 1.0s speech-like signal (multiple tones)
        speech_duration = 1.0
        speech_samples = int(speech_duration * sample_rate)
        t = np.linspace(0, speech_duration, speech_samples, endpoint=False)

        # Mix of fundamental and harmonics to simulate speech
        speech = (
            0.5 * np.sin(2 * np.pi * 200 * t) +  # fundamental
            0.3 * np.sin(2 * np.pi * 400 * t) +  # first harmonic
            0.2 * np.sin(2 * np.pi * 600 * t)    # second harmonic
        ).astype(np.float32)

        # Scale to -25 dBFS
        target_rms = 10**(-25.0 / 20)
        current_rms = np.sqrt(np.mean(speech**2))
        speech = speech * (target_rms / current_rms)

        # 0.5s more silence
        audio = np.concatenate([silence, speech, silence])

        # Run VAD
        segments, metrics = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-40.0,
            frame_ms=30, hop_ms=10, attack_ms=50, release_ms=200, min_active_ms=200
        )

        # Should detect the speech segment
        assert len(segments) >= 1

        # Primary segment should cover most of the speech
        primary = select_primary_segment(segments)
        assert primary is not None

        start_idx, end_idx = primary
        # Should start somewhere in or before the speech
        assert start_idx <= len(silence) + len(speech) // 2
        # Should end somewhere in or after the speech
        assert end_idx >= len(silence) + len(speech) // 2

        # Segment duration should be reasonable
        segment_duration = (end_idx - start_idx) / sample_rate
        assert 0.5 <= segment_duration <= 1.5

    def test_attack_release_timing(self):
        """Test that attack and release timing work as expected."""
        sample_rate = 16000

        # Create signal with sharp transitions
        noise1 = np.random.normal(0, 0.001, int(0.5 * sample_rate)).astype(np.float32)  # ~-60 dBFS
        tone = np.sin(2 * np.pi * 440 * np.linspace(0, 0.5, int(0.5 * sample_rate))).astype(np.float32) * 0.1  # ~-20 dBFS
        noise2 = np.random.normal(0, 0.001, int(0.5 * sample_rate)).astype(np.float32)  # ~-60 dBFS

        audio = np.concatenate([noise1, tone, noise2])

        # Test with fast attack/release
        segments_fast, _ = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-40.0,
            frame_ms=30, hop_ms=10, attack_ms=20, release_ms=20, min_active_ms=100
        )

        # Test with slow attack/release
        segments_slow, _ = detect_voiced_segments(
            audio, sample_rate, threshold_dbfs=-40.0,
            frame_ms=30, hop_ms=10, attack_ms=100, release_ms=100, min_active_ms=100
        )

        # Both should detect the tone, but timing may differ
        # This is mainly a regression test to ensure different parameters work
        assert isinstance(segments_fast, list)
        assert isinstance(segments_slow, list)